"""
FastAPI Server for Emergentica Voice Pipeline
=============================================

This server handles:
1. Webhook callbacks from Retell AI with real-time transcripts
2. Integration with the LangGraph orchestrator
3. Publishing results to the Streamlit dashboard

For Phase 2.1 (initial development), this uses mock logic.
For Phase 3 (integration), this connects to the real orchestrator.
"""

from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime
import json
import uvicorn
from pathlib import Path

from config import config

# Create FastAPI app
app = FastAPI(
    title="Emergentica Voice Server",
    description="Real-time voice-to-agent pipeline for emergency call processing",
    version="1.0.0"
)

print("üöÄ FastAPI app created")

# Add CORS middleware for Streamlit integration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================
# Request/Response Models
# ============================================

class RetellWebhookPayload(BaseModel):
    """Webhook payload from Retell AI Custom LLM."""
    interaction: dict  # Contains the conversation history
    call: Optional[dict] = None
    
    @property
    def call_id(self) -> str:
        """Extract call ID from payload."""
        if self.call:
            return self.call.get("call_id", "unknown")
        return "unknown"
    
    @property
    def transcript(self) -> str:
        """Extract user's last message from interaction."""
        # Get the last user message from interaction
        if "last_user_transcript" in self.interaction:
            return self.interaction["last_user_transcript"]
        return ""


class DispatchResponse(BaseModel):
    """Response sent back to Retell AI."""
    response: str  # Changed from response_text to match Retell API
    end_call: bool = False  # Changed from should_end_call to match Retell API




# ============================================
# WebSocket Endpoint for Retell Custom LLM
# ============================================

@app.websocket("/llm-websocket/{call_id}")
async def retell_llm_websocket(websocket: WebSocket, call_id: str):
    """
    WebSocket endpoint for Retell Custom LLM integration.
    This receives real-time transcripts and sends AI responses.
    """
    print(f"\n{'='*80}")
    print(f"üîå WebSocket Connection Attempt - Call ID: {call_id}")
    print(f"{'='*80}\n")
    
    # Track our own conversation history (Retell's transcript doesn't include AI responses!)
    our_conversation_history = []
    
    try:
        await websocket.accept()
        print(f"‚úÖ WebSocket accepted for call: {call_id}")
    except Exception as e:
        print(f"‚ùå Failed to accept WebSocket: {e}")
        import traceback
        traceback.print_exc()
        return
    
    try:
        # Import orchestrator
        try:
            from agents.orchestrator import get_orchestrator
            orchestrator = get_orchestrator()
        except ImportError:
            print("‚ö†Ô∏è Orchestrator not available, using mock responses")
            orchestrator = None
        
        # Send begin message (agent speaks first)
        begin_message = {
            "response_id": 0,
            "content": "Nine-nine-nine, what's your emergency?",
            "content_complete": True,
            "end_call": False
        }
        await websocket.send_json(begin_message)
        print("üì§ Sent begin message")
        
        # Listen for messages from Retell
        while True:
            data = await websocket.receive_json()
            
            interaction_type = data.get("interaction_type")
            response_id = data.get("response_id")
            transcript = data.get("transcript", [])
            
            print(f"\nüì• Received: {interaction_type}")
            
            if interaction_type == "update_only":
                # Just a transcript update, no response needed
                print(f"   Transcript update: {len(transcript)} messages")
                continue
            
            elif interaction_type == "response_required":
                # Need to send a response
                print(f"   Response required (ID: {response_id})")
                
                # Build conversation from Retell's transcript (user messages) + our history (AI responses)
                # Retell's transcript only has user messages, so we need to interleave with our responses
                
                # Get all user messages from Retell
                user_messages_from_retell = []
                for msg in transcript:
                    if msg.get("role") == "user":
                        content = msg.get("content", "")
                        if content:
                            user_messages_from_retell.append(content)
                
                # Build full conversation by interleaving user + AI messages
                full_conversation_messages = []
                for i, user_msg in enumerate(user_messages_from_retell):
                    full_conversation_messages.append(f"Caller: {user_msg}")
                    # Add our response if we have one for this turn
                    if i < len(our_conversation_history):
                        full_conversation_messages.append(f"Dispatcher: {our_conversation_history[i]}")
                
                # Get the last user message
                user_message = user_messages_from_retell[-1] if user_messages_from_retell else ""
                
                print(f"   User said: {user_message[:100]}...")
                print(f"   Full conversation has {len(full_conversation_messages)} exchanges")
                
                # Detect conversation loops (user confusion)
                loop_detected = False
                if len(our_conversation_history) >= 2:
                    # Check if last 2 dispatcher messages contain similar location questions
                    last_two = our_conversation_history[-2:]
                    location_keywords = ["address", "location", "where", "street", "building"]
                    
                    location_questions = sum(
                        1 for msg in last_two 
                        if any(keyword in msg.lower() for keyword in location_keywords) 
                        and "?" in msg
                    )
                    
                    if location_questions >= 2 and any(word in user_message.lower() for word in ["where", "location", "what", "?"]):
                        loop_detected = True
                        print("‚ö†Ô∏è LOOP DETECTED: User confused about location question")
                
                # Build full conversation context (include loop warning if detected)
                full_conversation = "\n\n".join(full_conversation_messages)
                if loop_detected:
                    full_conversation += "\n\n[SYSTEM ALERT: Caller seems confused by location question. Change your approach - give EXAMPLES instead of asking again. Say: 'I need your street address or building name - for example, 123 Main Street. What can you see around you?']"
                
                # Process through orchestrator if available
                if orchestrator and user_message:
                    try:
                        # Pass FULL conversation history for context
                        result = orchestrator.process_call(
                            call_id=call_id,
                            transcript=full_conversation
                        )
                        
                        # Use the actual AI-generated response from the agents
                        response_text = None
                        
                        # Check if we have a critical report (from triage agent)
                        if result.get('critical_report') and result['critical_report'].dispatcher_message:
                            response_text = result['critical_report'].dispatcher_message
                        
                        # Otherwise use info response (from info agent)
                        elif result.get('info_response') and result['info_response'].response:
                            response_text = result['info_response'].response
                        
                        # Fallback if no AI response available
                        if not response_text:
                            response_text = "I understand your situation. Can you please provide more details about your location and what's happening?"
                        
                        # Save our response to history so we remember what we said
                        our_conversation_history.append(response_text)
                        
                        # Build full conversation for dashboard (all messages including our latest response)
                        dashboard_conversation = []
                        for i, user_msg in enumerate(user_messages_from_retell):
                            dashboard_conversation.append(f"Caller: {user_msg}")
                            if i < len(our_conversation_history):
                                dashboard_conversation.append(f"Dispatcher: {our_conversation_history[i]}")
                        
                        dashboard_data = {
                            "call_id": call_id,
                            "transcript": "\n\n".join(dashboard_conversation),  # Full conversation
                            "latest_message": user_message,  # Just the latest user message
                            "timestamp": datetime.now().isoformat(),
                            "status": result['status'],
                            "classification": result['classification'].model_dump() if result['classification'] else None,
                            "critical_report": result['critical_report'].model_dump() if result['critical_report'] else None,
                            "info_response": result['info_response'].model_dump() if result['info_response'] else None,
                            "processing_time_ms": result['total_processing_time_ms'],
                            "route_taken": result['route_taken']
                        }
                        
                        data_dir = Path("data")
                        data_dir.mkdir(exist_ok=True)
                        with open(data_dir / "latest_call.json", "w") as f:
                            json.dump(dashboard_data, f, indent=2)
                        
                        print(f"‚úÖ Processed via {result['route_taken']}")
                        
                    except Exception as e:
                        print(f"‚ùå Error processing: {e}")
                        import traceback
                        traceback.print_exc()
                        response_text = "I apologize, we're experiencing technical difficulties. Let me transfer you to a human dispatcher."
                else:
                    # Fallback response
                    response_text = "I understand. Emergency services are being notified. Can you provide more details about your location?"
                
                # Send response back to Retell
                response = {
                    "response_id": response_id,
                    "content": response_text,
                    "content_complete": True,
                    "end_call": False
                }
                await websocket.send_json(response)
                print(f"üì§ Sent response: {response_text[:100]}...")
            
            elif interaction_type == "reminder_required":
                # User hasn't spoken in a while
                response = {
                    "response_id": response_id,
                    "content": "Are you still there? Please describe your emergency.",
                    "content_complete": True,
                    "end_call": False
                }
                await websocket.send_json(response)
                print("üì§ Sent reminder")
    
    except WebSocketDisconnect:
        print(f"\n{'='*80}")
        print(f"üìû Call ended - Call ID: {call_id}")
        print(f"{'='*80}\n")
    
    except Exception as e:
        print(f"‚ùå WebSocket error: {e}")
        import traceback
        traceback.print_exc()
        try:
            await websocket.close()
        except:
            pass

print("üîå WebSocket route registered at /llm-websocket/{call_id}")

# ============================================
# Phase 2.1: Mock Implementation
# ============================================

@app.post("/webhook/retell", response_model=DispatchResponse)
async def retell_webhook_mock(payload: RetellWebhookPayload):
    """
    PHASE 2.1: Mock webhook handler for testing voice pipeline.
    
    This version simply echoes back the transcript to verify the
    Twilio ‚Üí Retell ‚Üí FastAPI pipeline is working.
    
    In Phase 3, this will be replaced with real orchestrator integration.
    """
    
    print("=" * 80)
    print("üìû INCOMING CALL (MOCK MODE)")
    print("=" * 80)
    print(f"Call ID: {payload.call_id}")
    print(f"Transcript:\n{payload.transcript}")
    print("=" * 80)
    
    # Mock response
    response_text = f"Thank you for calling. I heard: {payload.transcript[:100]}... Emergency services have been notified."
    
    # Save to file for dashboard testing
    mock_data = {
        "call_id": payload.call_id,
        "transcript": payload.transcript,
        "timestamp": datetime.now().isoformat(),
        "status": "MOCK_PROCESSING",
        "mock_response": response_text
    }
    
    # Write to latest_call.json for dashboard
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    with open(data_dir / "latest_call.json", "w") as f:
        json.dump(mock_data, f, indent=2)
    
    print(f"‚úÖ Mock response generated and saved to data/latest_call.json")
    
    return DispatchResponse(
        response_text=response_text,
        should_end_call=False
    )


# ============================================
# Phase 3: Real Implementation (Placeholder)
# ============================================

@app.post("/webhook/retell/live", response_model=DispatchResponse)
async def retell_webhook_live(payload: RetellWebhookPayload):
    """
    PHASE 3: Real webhook handler with orchestrator integration.
    
    This will be activated in Phase 3 when integrating the full system.
    """
    
    # Import here to avoid errors if not yet ready
    try:
        from agents.orchestrator import get_orchestrator
    except ImportError:
        raise HTTPException(
            status_code=503,
            detail="Orchestrator not available. Use /webhook/retell for mock mode."
        )
    
    print("=" * 80)
    print("üìû INCOMING LIVE CALL")
    print("=" * 80)
    print(f"Call ID: {payload.call_id}")
    print(f"Transcript length: {len(payload.transcript)} chars")
    print("=" * 80)
    
    try:
        # Process through orchestrator
        orchestrator = get_orchestrator()
        result = orchestrator.process_call(
            call_id=payload.call_id,
            transcript=payload.transcript
        )
        
        # Generate response based on severity
        if result['classification']:
            severity = result['classification'].severity
            
            if severity == "CRITICAL_EMERGENCY":
                response_text = "This is a critical emergency. All available units have been dispatched to your location. Please stay on the line and follow my instructions."
            elif severity == "STANDARD_ASSISTANCE":
                response_text = "Help is on the way. An officer has been dispatched to assist you."
            else:
                response_text = "Thank you for calling. We'll send someone to check on this situation."
        else:
            response_text = "Emergency services have been notified. Please stay safe."
        
        # Save full result for dashboard
        dashboard_data = {
            "call_id": payload.call_id,
            "transcript": payload.transcript,
            "timestamp": datetime.now().isoformat(),
            "status": result['status'],
            "classification": result['classification'].model_dump() if result['classification'] else None,
            "critical_report": result['critical_report'].model_dump() if result['critical_report'] else None,
            "info_response": result['info_response'].model_dump() if result['info_response'] else None,
            "processing_time_ms": result['total_processing_time_ms'],
            "route_taken": result['route_taken']
        }
        
        # Write to latest_call.json for dashboard
        data_dir = Path("data")
        data_dir.mkdir(exist_ok=True)
        
        with open(data_dir / "latest_call.json", "w") as f:
            json.dump(dashboard_data, f, indent=2)
        
        print(f"‚úÖ Call processed successfully: {result['route_taken']}")
        print(f"   Processing time: {result['total_processing_time_ms']}ms")
        
        return DispatchResponse(
            response=response_text,
            end_call=False
        )
    
    except Exception as e:
        print(f"‚ùå Error processing call: {e}")
        import traceback
        traceback.print_exc()
        
        # Save error to dashboard
        error_data = {
            "call_id": payload.call_id,
            "transcript": payload.transcript,
            "timestamp": datetime.now().isoformat(),
            "status": "ERROR",
            "error": str(e)
        }
        
        with open(Path("data") / "latest_call.json", "w") as f:
            json.dump(error_data, f, indent=2)
        
        return DispatchResponse(
            response="I apologize, we're experiencing technical difficulties. Transferring you to a human dispatcher.",
            end_call=False
        )


# ============================================
# Retell Web SDK Token Generation
# ============================================

@app.post("/api/retell/token")
async def get_retell_token():
    """
    Generate Retell access token for web SDK.
    This allows the web interface to initiate calls.
    """
    import requests
    
    try:
        # Call Retell API to create a new call
        response = requests.post(
            "https://api.retellai.com/v2/create-web-call",
            headers={
                "Authorization": f"Bearer {config.RETELL_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "agent_id": config.RETELL_AGENT_ID
            }
        )
        
        response.raise_for_status()
        data = response.json()
        
        return {
            "access_token": data.get("access_token"),
            "call_id": data.get("call_id")
        }
        
    except Exception as e:
        print(f"‚ùå Error generating Retell token: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate Retell token: {str(e)}"
        )


@app.post("/api/retell/make-call")
async def make_phone_call(request: Request):
    """
    Initiate an outbound phone call using Retell.
    The AI agent will call the specified phone number.
    """
    import requests
    
    try:
        body = await request.json()
        phone_number = body.get("phone_number")
        
        if not phone_number:
            raise HTTPException(status_code=400, detail="phone_number is required")
        
        print(f"üìû Initiating call to: {phone_number}")
        
        # Call Retell API to create a phone call
        response = requests.post(
            "https://api.retellai.com/v2/create-phone-call",
            headers={
                "Authorization": f"Bearer {config.RETELL_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "from_number": config.RETELL_PHONE_NUMBER,  # Your Retell phone number
                "to_number": phone_number,
                "agent_id": config.RETELL_AGENT_ID,
                "override_agent_id": config.RETELL_AGENT_ID
            }
        )
        
        response.raise_for_status()
        data = response.json()
        
        print(f"‚úÖ Call initiated! Call ID: {data.get('call_id')}")
        
        return {
            "success": True,
            "call_id": data.get("call_id"),
            "status": "initiated",
            "to_number": phone_number
        }
        
    except requests.exceptions.HTTPError as e:
        error_detail = e.response.text if hasattr(e.response, 'text') else str(e)
        print(f"‚ùå Retell API error: {error_detail}")
        raise HTTPException(
            status_code=e.response.status_code if hasattr(e, 'response') else 500,
            detail=f"Retell API error: {error_detail}"
        )
    except Exception as e:
        print(f"‚ùå Error making phone call: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to initiate call: {str(e)}"
        )


# ============================================
# Health & Status Endpoints
# ============================================

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "service": "Emergentica Voice Server",
        "timestamp": datetime.now().isoformat()
    }


@app.post("/")
async def root_webhook(request: Request):
    """
    Handle Retell general webhook events (call_started, call_ended, etc.)
    This receives call lifecycle events, not live transcripts.
    """
    try:
        body = await request.json()
        event_type = body.get("event")
        call_data = body.get("call", {})
        call_id = call_data.get("call_id")
        
        print(f"\n{'='*60}")
        print(f"üìû RETELL EVENT: {event_type}")
        print(f"Call ID: {call_id}")
        
        if event_type == "call_started":
            print(f"‚úÖ Call started")
            print(f"Agent: {call_data.get('agent_name')}")
            
        elif event_type == "call_ended":
            transcript = call_data.get("transcript", "")
            duration = call_data.get("duration_ms", 0) / 1000
            
            print(f"üìû Call ended")
            print(f"Duration: {duration:.1f}s")
            print(f"Transcript: {transcript[:200]}...")
            
            # Save call summary to dashboard
            call_summary = {
                "call_id": call_id,
                "timestamp": datetime.now().isoformat(),
                "duration_seconds": duration,
                "transcript": transcript,
                "status": "completed"
            }
            
            # Save to calls.json for dashboard
            calls_file = Path("calls.json")
            calls = []
            if calls_file.exists():
                with open(calls_file, 'r') as f:
                    calls = json.load(f)
            
            calls.append(call_summary)
            
            with open(calls_file, 'w') as f:
                json.dump(calls[-50:], f, indent=2)  # Keep last 50 calls
            
            print(f"üíæ Saved call summary to dashboard")
        
        print(f"{'='*60}\n")
        
        return {"status": "success", "event": event_type}
        
    except Exception as e:
        print(f"‚ùå Error processing webhook: {e}")
        return {"status": "error", "message": str(e)}


@app.get("/status")
async def status():
    """Detailed status information."""
    
    # Check if orchestrator is available
    orchestrator_available = False
    try:
        from agents.orchestrator import get_orchestrator
        orchestrator_available = True
    except:
        pass
    
    # Check configuration
    config_status = {
        "holistic_ai": bool(config.HOLISTIC_AI_TEAM_ID and config.HOLISTIC_AI_API_TOKEN),
        "twilio": bool(config.TWILIO_ACCOUNT_SID and config.TWILIO_AUTH_TOKEN),
        "retell": bool(config.RETELL_API_KEY and config.RETELL_AGENT_ID),
        "langsmith": bool(config.LANGSMITH_API_KEY)
    }
    
    return {
        "status": "operational",
        "orchestrator_available": orchestrator_available,
        "configuration": config_status,
        "endpoints": {
            "mock_webhook": "/webhook/retell (Phase 2.1)",
            "live_webhook": "/webhook/retell/live (Phase 3)"
        },
        "timestamp": datetime.now().isoformat()
    }


@app.get("/")
async def root():
    """Root endpoint with API information."""
    return {
        "service": "Emergentica Voice Server",
        "version": "1.0.0",
        "description": "Real-time emergency call processing with AI agents",
        "endpoints": {
            "health": "/health",
            "status": "/status",
            "docs": "/docs",
            "mock_webhook": "/webhook/retell",
            "live_webhook": "/webhook/retell/live",
            "latest_call": "/api/latest-call"
        }
    }


@app.get("/api/latest-call")
async def get_latest_call():
    """Get the latest call data for the dashboard."""
    try:
        call_file = Path("data/latest_call.json")
        if call_file.exists():
            with open(call_file, "r") as f:
                return json.load(f)
        else:
            raise HTTPException(status_code=404, detail="No call data available")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/config")
async def get_config():
    """Get public configuration for the dashboard."""
    return {
        "geocode_api_key": config.GEOCODE_API_KEY
    }


@app.get("/api/benchmark")
async def get_benchmark_results():
    """Get benchmark results for Track A demonstration."""
    try:
        # Check if benchmark results exist
        benchmark_file = Path("data/benchmark_results.json")
        if benchmark_file.exists():
            with open(benchmark_file, "r") as f:
                return json.load(f)
        else:
            # Return mock benchmark data if no real results exist
            return {
                "status": "demo_data",
                "test_date": datetime.now().isoformat(),
                "total_calls_tested": 50,
                "routing_accuracy": 96.0,
                "avg_routing_latency_ms": 847,
                "avg_critical_triage_ms": 2341,
                "cost_efficiency_vs_sonnet": 67.3,
                "performance_metrics": {
                    "critical_emergency_accuracy": 98.5,
                    "standard_assistance_accuracy": 95.2,
                    "non_emergency_accuracy": 94.8,
                    "avg_response_time_ms": 1594
                },
                "cost_breakdown": {
                    "total_cost_usd": 0.042,
                    "cost_per_call_usd": 0.00084,
                    "vs_sonnet_only_usd": 0.128,
                    "savings_percentage": 67.3
                },
                "model_distribution": {
                    "router_agent": "Claude 3.5 Haiku",
                    "triage_agent": "Claude 3.5 Haiku",
                    "info_agent": "Claude 3.5 Haiku"
                },
                "track_a_compliance": {
                    "performance": "‚úì High accuracy (96%)",
                    "robustness": "‚úì Consistent <3s response",
                    "cost_efficiency": "‚úì 67% cost reduction"
                }
            }
    except Exception as e:
        print(f"‚ùå Error loading benchmark: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/dashboard", response_class=HTMLResponse)
async def serve_dashboard():
    """Serve the dispatch dashboard HTML."""
    try:
        dashboard_file = Path("dispatch_dashboard.html")
        if dashboard_file.exists():
            with open(dashboard_file, "r", encoding="utf-8") as f:
                return f.read()
        else:
            raise HTTPException(status_code=404, detail="Dashboard not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# Main Entry Point
# ============================================

if __name__ == "__main__":
    """
    Run the FastAPI server.
    
    For development:
        python main.py
    
    For production:
        uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    """
    
    print("=" * 80)
    print("üöÄ Emergentica Voice Server Starting...")
    print("=" * 80)
    print(f"Host: {config.FASTAPI_HOST}")
    print(f"Port: {config.FASTAPI_PORT}")
    print("\nEndpoints:")
    print(f"  ‚Ä¢ API Docs: http://localhost:{config.FASTAPI_PORT}/docs")
    print(f"  ‚Ä¢ Health: http://localhost:{config.FASTAPI_PORT}/health")
    print(f"  ‚Ä¢ Status: http://localhost:{config.FASTAPI_PORT}/status")
    print(f"  ‚Ä¢ Mock Webhook: http://localhost:{config.FASTAPI_PORT}/webhook/retell")
    print(f"  ‚Ä¢ Live Webhook: http://localhost:{config.FASTAPI_PORT}/webhook/retell/live")
    print("=" * 80)
    
    uvicorn.run(
        "main:app",
        host=config.FASTAPI_HOST,
        port=config.FASTAPI_PORT,
        reload=True
    )
